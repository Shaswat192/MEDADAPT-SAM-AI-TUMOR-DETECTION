# MedAdapt-SAM Quick Start Guide

## ğŸš€ Getting Started

### 1. Installation

```bash
# Navigate to project directory
cd "D:\project major\MedAdapt-SAM"

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Download SAM Checkpoint

Download the SAM checkpoint and place it in the `checkpoints` folder:

```bash
# Create checkpoints directory
mkdir checkpoints

# Download SAM ViT-B checkpoint
# Visit: https://github.com/facebookresearch/segment-anything#model-checkpoints
# Download sam_vit_b_01ec64.pth and place in checkpoints/
```

### 3. Verify Dataset

Your dataset is already prepared at:
```
D:\major projrct PNG folder\brats_png
```

Total images: **276,267 PNG images**
Patient cases: **1,252**

### 4. Train Baseline Model (U-Net)

```bash
# Train U-Net baseline
python training/train_unet.py --config configs/config.yaml --device cuda

# Monitor training with TensorBoard
tensorboard --logdir logs/unet
```

### 5. Train SAM Adapter

```bash
# Train SAM with adapters
python training/train_adapter.py --config configs/config.yaml --device cuda
```

### 6. Evaluate Models

```bash
# Evaluate all models
python evaluation/evaluate_all.py --checkpoint checkpoints/unet_best.pth
```

### 7. Launch Streamlit Demo

```bash
# Run the web application
streamlit run streamlit_app/app.py
```

The app will open at: `http://localhost:8501`

## ğŸ“Š Project Phases

### âœ… Phase 1: Dataset Preparation
- Dataset already prepared with 276,267 images
- BraTS 2021 PNG format
- ET, TC, WT masks available

### ğŸ”„ Phase 2: Baseline Models (Current)
- **U-Net**: Implemented âœ…
- **Training Script**: Ready âœ…
- **Metrics**: Dice, IoU, HD95 âœ…

### ğŸ”„ Phase 3: Prompt Sensitivity Study
- Box prompts âœ…
- Point prompts âœ…
- Hybrid prompts âœ…

### ğŸ”„ Phase 4: Model Stabilization
- Adapter freezing implemented âœ…
- Best prompt strategy selection pending

### ğŸ”„ Phase 5: Uncertainty-Guided Refinement
- Monte Carlo Dropout âœ…
- Deep Ensembles âœ…
- Iterative refinement âœ…

### ğŸ”„ Phase 6-7: Automatic Prompting
- Semi-automatic pipeline âœ…
- Fully automatic generation âœ…

### ğŸ”„ Phase 8: Explainable AI
- Attention visualization (pending)
- Prompt influence analysis (pending)

### ğŸ”„ Phase 9: LLM Integration
- RAG system (pending)
- Clinical explanations (pending)

### ğŸ”„ Phase 10: Deployment
- Streamlit app âœ…
- Interactive interface âœ…

## ğŸ¯ Quick Commands

### Test Dataset Loader
```bash
python data/dataset_loader.py
```

### Test U-Net Model
```bash
python models/unet.py
```

### Test Metrics
```bash
python evaluation/metrics.py
```

### Test Prompt Generation
```bash
python prompts/prompt_generator.py
```

### Test Uncertainty Estimation
```bash
python uncertainty/uncertainty_estimation.py
```

## ğŸ“ Project Structure

```
MedAdapt-SAM/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml              # Configuration file
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset_loader.py        # Dataset loading
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ unet.py                  # U-Net baseline
â”‚   â”œâ”€â”€ sam_adapter.py           # SAM with adapters
â”‚   â””â”€â”€ prompt_generator.py      # Automatic prompts
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ train_unet.py            # U-Net training
â”‚   â””â”€â”€ train_adapter.py         # Adapter training
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ metrics.py               # Evaluation metrics
â”‚   â””â”€â”€ evaluator.py             # Model evaluation
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ prompt_generator.py      # Prompt generation
â”œâ”€â”€ uncertainty/
â”‚   â””â”€â”€ uncertainty_estimation.py # Uncertainty tools
â”œâ”€â”€ streamlit_app/
â”‚   â””â”€â”€ app.py                   # Web interface
â”œâ”€â”€ checkpoints/                 # Model checkpoints
â”œâ”€â”€ results/                     # Experiment results
â”œâ”€â”€ logs/                        # Training logs
â””â”€â”€ requirements.txt             # Dependencies
```

## ğŸ”§ Configuration

Edit `configs/config.yaml` to customize:
- Dataset paths
- Model architecture
- Training hyperparameters
- Prompt strategies
- Uncertainty settings

## ğŸ“ˆ Monitoring Training

### TensorBoard
```bash
tensorboard --logdir logs
```

### Weights & Biases (Optional)
```bash
# Set up wandb
wandb login
# Training will automatically log to wandb
```

## ğŸ› Troubleshooting

### CUDA Out of Memory
- Reduce batch size in `configs/config.yaml`
- Use smaller image size (e.g., 128 instead of 256)

### Dataset Not Found
- Verify path in config: `D:/major projrct PNG folder/brats_png`
- Check that PNG files exist

### SAM Checkpoint Missing
- Download from: https://github.com/facebookresearch/segment-anything
- Place in `checkpoints/` folder

## ğŸ“š Next Steps

1. **Train baseline models** (U-Net, SAM)
2. **Run prompt sensitivity study**
3. **Implement automatic prompting**
4. **Add explainability features**
5. **Integrate LLM for explanations**
6. **Deploy final demo**

## ğŸ’¡ Tips

- Start with U-Net baseline to verify pipeline
- Use smaller dataset subset for quick testing
- Monitor metrics during training
- Save checkpoints regularly
- Test on validation set before final evaluation

## ğŸ“ Support

For issues or questions:
- Check documentation in README.md
- Review code comments
- Test individual modules

---

**Happy Training! ğŸ§ ğŸš€**
